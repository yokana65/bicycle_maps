---
title: "Building Bicycle Maps"
author: "Johannes Wagner"
date: "`r Sys.Date()`"
---

```{r, messages = FALSE}
library(tidyverse)     # ggplot, dplyr, and friends
library(sf)            # Handle spatial data in R in a tidy way
library(tidygeocoder)  # Automated geocoding
library(osrm)          # Access OSRM through R
library(ggrepel)       # Nicer non-overlapping labels
library(glue)          # Easier string interpolation
library(scales)        # Nicer labeling functions
library(patchwork)     # Combine plots nicely
library(ggspatial)     # Nicer map features like scale bars
library(httr)          # HTTP requests
```

This builds on the geocoding tutorial from [Andrew Heiss](https://www.andrewheiss.com/blog/2023/06/01/geocoding-routing-openstreetmap-r/) and extends its 
implementation to use CI and a reproducible approach.

The main idea despite the DevOps technicalities is to train the data gathering aspect of bike maps and build pipelines regarding this task.

Write a function for setting up the theme configuration for the ggplot maps.

```{r}
theme_roadtrip <- function() {
  theme_void(base_family = "Overpass Light") +
    theme(
      plot.title = element_text(family = "Overpass", face = "bold", hjust = 0.5),
      strip.text = element_text(
        family = "Overpass ExtraBold", face = "plain",
        size = rel(1.1), hjust = 0.5)
    )
}

# Make labels use Overpass by default
update_geom_defaults("label_repel", 
                     list(family = "Overpass",
                          fontface = "plain"))
update_geom_defaults("label", 
                     list(family = "Overpass",
                          fontface = "plain"))

update_geom_defaults("text_repel", 
                     list(family = "Overpass",
                          fontface = "plain"))
update_geom_defaults("text", 
                     list(family = "Overpass",
                          fontface = "plain"))

# Yellowstone colors
clrs <- NatParksPalettes::natparks.pals("Yellowstone")
```

We also want to define some general format functionality: 

```{r}
fmt_duration <- function(x) {
  # Round to the nearest 15 minutes
  n_seconds <- round(seconds(x * 60) / (15 * 60)) * (15 * 60)
  n_seconds <- seconds_to_period(n_seconds)
  
  out <- map_chr(n_seconds, \(n) {
    if (seconds(n) <= 59) {
      # If this is less than an hour, don't format anything with hours
      glue("{MM} minutes", MM = minute(n))
    } else {
      # I only want to format this as a number of hours. If the duration is
      # longer than 24 hours, seconds_to_period() rolls over into days (i.e.
      # seconds_to_period(60 * 60 * 24) returns "1d 0H 0M 0S"), and it shows
      # zero hours. So we extract the day part of the period, multiply it by 24,
      # and add it to the hour component that we want to display
      extra_day_hours <- day(n) * 24
  
      glue("{HH} hour{s} {MM} minutes",
        HH = scales::label_comma()(hour(n) + extra_day_hours),
        MM = minute(n),
        s = ifelse(hour(n) == 1, "", "s")
      )
    }
  })
  
  return(out)
}

fmt_miles <- scales::label_number(accuracy = 10, suffix = " miles", big.mark = ",")

miles_to_meters <- function(x) {
  x * 1609.344
}

meters_to_miles <- function(x) {
  x / 1609.344
}

km_to_miles <- function(x) {
  meters_to_miles(x * 1000)
}
```

## Community data

This is something that has a multitude of sources depending on the national context. We will start with Germany and then try to extend it to the European context.

In Germany municipality data is provided by the [BKG](https://gdz.bkg.bund.de/index.php/default/digitale-geodaten/verwaltungsgebiete/verwaltungsgebiete-1-250-000-stand-01-01-vg250-01-01.html) and can be downloaded
as shapefile or geopackage. We need to convert them into a `data.frame`or a `tibble`.

```{r}
# Get the ZIP file from BKG
# url <- "https://daten.gdz.bkg.bund.de/produkte/vg/vg250_ebenen_0101/aktuell/vg250_01-01.utm32s.shape.ebenen.zip"

# response <- GET(url)

# if (response$status_code == 200) {
#   writeBin(response$content, "data/shapefile.zip")
# } else {
#   stop("Could not download zip file")
# }

# # Unzip the file
# unzip(shapefile.zip)
# Zip file is preprocessed
home_directory = Sys.getenv("HOME")

working_directory = paste(home_directory, "/Documents/github/bicycle_maps/data", sep="")

setwd(working_directory)

# Get the municipality shapefile
municipalities <- st_read("VG250_KRS.shp")
# str(municipalities)

# Convert the shapefile into a tibble
municipalities_tb <- as_tibble(municipalities) %>% select(OBJID, GEN, SN_L, geometry)

# # filter the layer of interest
# lower_48 <- us_states %>% 
#   filter(!(NAME %in% c("Alaska", "Hawaii", "Puerto Rico")))
```

For europe, we could got to http://ec.europa.eu/eurostat/cache/GISCO/distribution/v2/nuts/geojson/NUTS_RG or use the eurostat package.

```{r, eval=FALSE, message=FALSE, warning=FALSE}
library(eurostat)

data <- get_eurostat_geospatial(
  output_class = "sf",
  resolution = "60",
  nuts_level = "all",
  year = "2016",
  cache = TRUE,
  update_cache = FALSE,
  cache_dir = NULL,
  crs = "4326",
  make_valid = FALSE
)
```

We also want to select the area, where we want to map our route. One way is to use the SN_L column of the data set. This is a column that contains the name of the state.
The List of federal states in Germany is: 
01 - SH
02 - HH
03- NI
04 - HB
05 - NW
06- HE
07- RP
08- BW
09- BY
10- SL
11- BE
12- BB
13- MV
14 - SN
15 - ST
16 - TH


```{r}
cols <- c("SN_L")
municipalities_tb[cols] <- lapply(municipalities_tb[cols], factor) 
summary(municipalities_tb$SN_L)
```

For this example we want to filter out Sachsony (SN) and Thuringia (TH). We can do this by using the `filter` function from the `dplyr` package.

```{r}
municipalities_tb <- municipalities_tb %>% 
  filter(SN_L %in% c("14", "15", "16"))
```


In general we want to use the ggplot library to plot our data.

```{r}
ggplot() + 
  geom_sf(data = municipalities_tb, aes(geometry = geometry)) +
  coord_sf(crs = st_crs("EPSG:25832")) +  # UTM 32N
  theme_roadtrip()
```

## Routing

First we want to get our route by names of locations that we pass:

```{r}
stops_to_geocode <- tribble(
  ~direction,   ~day, ~location,
  "There",      1,    "Leipzig",
  "There",      2,    "Lützen",
  "There",      3,    "Bothfeld, Lützen",
  "There",      4,    "Kriechau, Weißenfels",
  "There",      5,    "Weißenfels",
  "There",      6,    "Eulau, Naumburg",
  "There",      7,    "Naumburg",
  "There",      8,    "Bad Kösen",
  "There",      9,    "Groheringen",
  "There",      10,    "Bad Sulza",
  "There",      11,    "Auerstedt",
  "Back again", 1,    "Auerstedt",
  "Back again", 2,    "Bad Sulza",
  "Back again", 3,    "Sonnendorf",
  "Back again", 4,    "Jena",
  "Back again", 5,    "Halle",
  "Back again", 6,    "Leipzig"
)  %>% 
  mutate(direction = fct_inorder(direction))
```

We can now use the `geocode` package to retrieve the spatial data for our locations. Be aware that nomatim coordinates are in WGS 84 (EPSG:4326) and we need to transform them to UTM 32N (EPSG:25832) to be able to plot them on our map.

```{r}
stops_geocoded <- stops_to_geocode %>% 
  geocode(location, method = "osm") %>%
  filter(!is.na(long) & !is.na(lat)) %>%
  st_as_sf(coords = c("long", "lat"), crs = st_crs("EPSG:4326"))
```

Remove the last line of our journay:

```{r}
all_stops_unique <- stops_geocoded %>% 
  slice(1:(n() - 1))
```

Also lets do the reprojection:

```{r}
crs <- st_crs(municipalities_tb$geometry)
all_stops_unique["geometry"] <- lapply(all_stops_unique["geometry"], st_transform, crs) 
```

## First Map

```{r}
ggplot() +
  geom_sf(data = municipalities_tb, aes(geometry = geometry)) +
  geom_sf(data = all_stops_unique) +
  geom_label_repel(
    data = all_stops_unique,
    aes(label = location, geometry = geometry),
    stat = "sf_coordinates", seed = 1234,
    size = 3, segment.color = clrs[3], min.segment.length = 0,
    max.overlaps = 20
  ) +
  annotation_scale(
    location = "bl", bar_cols = c("grey30", "white"),
    unit_category = "imperial", text_family = "Overpass"
  ) +
  coord_sf(crs = st_crs("EPSG:25832")) +  
  theme_roadtrip()
```